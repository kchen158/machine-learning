{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 242 hw5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implement stochastic gradient descent for logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Apply SGD algorithm to the un-normalized training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stochastic gradient descent: $\\textbf{w}=\\textbf{w}+\\alpha(t_i-h_\\textbf{w}(\\textbf{x}_i))\\textbf{x}_i$\n",
    "\n",
    "$h_\\textbf{w}(\\textbf{x})=\\sigma(\\textbf{wx})=\\frac{1}{1+\\text{exp}(-\\textbf{wx})}$\n",
    "\n",
    "log likelihood: $\\text{log}(L(\\textbf{w}))=\\sum^{N}_{i=1}t_i\\text{log}(h_\\textbf{w}(\\textbf{x}_i))+(1-t_i)\\text{log}(1-h_\\textbf{w}(\\textbf{x}_i))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>time</th>\n",
       "      <th>epoch</th>\n",
       "      <th>training error</th>\n",
       "      <th>test error</th>\n",
       "      <th>training log likelihood</th>\n",
       "      <th>test log likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>0.152737</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.332248</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>-0.625571</td>\n",
       "      <td>-0.626731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.000000e-07</td>\n",
       "      <td>0.229979</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.332248</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>-0.626092</td>\n",
       "      <td>-0.628160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>1.217481</td>\n",
       "      <td>268.0</td>\n",
       "      <td>0.327362</td>\n",
       "      <td>0.337662</td>\n",
       "      <td>-0.625238</td>\n",
       "      <td>-0.627682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           step      time  epoch  training error  test error  \\\n",
       "0  1.000000e-06  0.152737   29.0        0.332248    0.363636   \n",
       "1  5.000000e-07  0.229979   49.0        0.332248    0.357143   \n",
       "2  1.000000e-07  1.217481  268.0        0.327362    0.337662   \n",
       "\n",
       "   training log likelihood  test log likelihood  \n",
       "0                -0.625571            -0.626731  \n",
       "1                -0.626092            -0.628160  \n",
       "2                -0.625238            -0.627682  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "data = pd.read_csv('diabetes.csv', header=0)\n",
    "x = data.iloc[:, :-1].values\n",
    "x = np.c_[np.ones(x.shape[0]), x]  # add bias component column\n",
    "y = data.iloc[:, -1].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=0)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def loss(x, y, w):\n",
    "    h_w = sigmoid(x @ w)\n",
    "    return -np.mean(y * np.log(h_w) + (1 - y) * np.log(1 - h_w))\n",
    "\n",
    "def shuffle_data(x, y):\n",
    "    data = np.c_[x, y]\n",
    "    np.random.shuffle(data)\n",
    "    return data[:, :-1], data[:, -1]\n",
    "\n",
    "def predict(x, w):\n",
    "    prob = sigmoid(x @ w)\n",
    "    return (prob >= 0.5).astype(int)\n",
    "\n",
    "def report(x_train, x_test, w):\n",
    "    error_train = np.mean(predict(x_train, w) != y_train)\n",
    "    error_test = np.mean(predict(x_test, w) != y_test)\n",
    "    llh_train = - loss(x_train, y_train, w)\n",
    "    llh_test = - loss(x_test, y_test, w)\n",
    "    return [error_train, error_test, llh_train, llh_test]\n",
    "    \n",
    "def sgd(x, y, alpha=0.001, converge=1e-5):\n",
    "    k = 0  # instance count\n",
    "    e = 1  # epoch count\n",
    "    n = len(y)\n",
    "    w = np.zeros(x.shape[1])\n",
    "    l = loss(x, y, w)\n",
    "    l_list = [l]\n",
    "    while True:        \n",
    "        h_w = sigmoid(x[k, :] @ w)\n",
    "        w += alpha * (y[k] - h_w) * x[k, :]\n",
    "        k += 1\n",
    "        if k >= n:\n",
    "            k = 0\n",
    "            e += 1\n",
    "            x, y = shuffle_data(x, y)\n",
    "            l = loss(x, y, w)\n",
    "            l_list.append(l)\n",
    "            if abs(l_list[-1] - l_list[-2]) < converge:  # converge criterion\n",
    "                break       \n",
    "    return l_list, w, e\n",
    "\n",
    "step = [0.000001, 0.0000005, 0.0000001]\n",
    "l_list = []\n",
    "w_list = []\n",
    "result = []\n",
    "for s in step:\n",
    "    start = time.time()\n",
    "    l, w, e = sgd(x_train, y_train, alpha=s)\n",
    "    t = round(time.time() - start, 6)\n",
    "    r = report(x_train, x_test, w)\n",
    "    l_list.append(l)\n",
    "    w_list.append(w)\n",
    "    result.append(np.r_[t, e, r])\n",
    "\n",
    "for i in range(len(l_list)):\n",
    "    plt.plot(l_list[i], label='step=' + str(step[i]))\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig('sgd.png', dpi=270)\n",
    "plt.show()\n",
    "result = np.c_[step, result]\n",
    "result = pd.DataFrame(result, columns=['step', 'time', 'epoch', 'training error', 'test error',\n",
    "                                     'training log likelihood', 'test log likelihood'])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>bias</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e-06</td>\n",
       "      <td>-0.001647</td>\n",
       "      <td>0.009288</td>\n",
       "      <td>0.010924</td>\n",
       "      <td>-0.028182</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>-0.001563</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.000000e-07</td>\n",
       "      <td>-0.001175</td>\n",
       "      <td>0.006467</td>\n",
       "      <td>0.010188</td>\n",
       "      <td>-0.026180</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>-0.002115</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>-0.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000e-07</td>\n",
       "      <td>-0.000657</td>\n",
       "      <td>0.003352</td>\n",
       "      <td>0.008033</td>\n",
       "      <td>-0.021251</td>\n",
       "      <td>-0.001020</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>-0.002466</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>-0.001078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           step      bias  Pregnancies   Glucose  BloodPressure  \\\n",
       "0  1.000000e-06 -0.001647     0.009288  0.010924      -0.028182   \n",
       "1  5.000000e-07 -0.001175     0.006467  0.010188      -0.026180   \n",
       "2  1.000000e-07 -0.000657     0.003352  0.008033      -0.021251   \n",
       "\n",
       "   SkinThickness   Insulin       BMI  DiabetesPedigreeFunction       Age  \n",
       "0       0.002382  0.001646 -0.001563                  0.000256  0.000372  \n",
       "1       0.000894  0.001510 -0.002115                  0.000174 -0.000332  \n",
       "2      -0.001020  0.001470 -0.002466                  0.000085 -0.001078  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.r_[['step', 'bias'], data.columns[:-1]]\n",
    "weights = pd.DataFrame(np.c_[step, w_list], columns=features)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Apply SGD algorithm to the normalized training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>time</th>\n",
       "      <th>epoch</th>\n",
       "      <th>training error</th>\n",
       "      <th>test error</th>\n",
       "      <th>training log likelihood</th>\n",
       "      <th>test log likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00050</td>\n",
       "      <td>0.271201</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.348534</td>\n",
       "      <td>0.350649</td>\n",
       "      <td>-0.646435</td>\n",
       "      <td>-0.647755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.776652</td>\n",
       "      <td>174.0</td>\n",
       "      <td>0.348534</td>\n",
       "      <td>0.350649</td>\n",
       "      <td>-0.646822</td>\n",
       "      <td>-0.648056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>1.309833</td>\n",
       "      <td>293.0</td>\n",
       "      <td>0.348534</td>\n",
       "      <td>0.350649</td>\n",
       "      <td>-0.647203</td>\n",
       "      <td>-0.648383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      step      time  epoch  training error  test error  \\\n",
       "0  0.00050  0.271201   53.0        0.348534    0.350649   \n",
       "1  0.00010  0.776652  174.0        0.348534    0.350649   \n",
       "2  0.00005  1.309833  293.0        0.348534    0.350649   \n",
       "\n",
       "   training log likelihood  test log likelihood  \n",
       "0                -0.646435            -0.647755  \n",
       "1                -0.646822            -0.648056  \n",
       "2                -0.647203            -0.648383  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv('diabetes.csv', header=0)\n",
    "x = data.iloc[:, :-1].values\n",
    "x_norm = normalize(x, axis=0)  # normalized data before split training and test sets\n",
    "x_norm = np.c_[np.ones(x_norm.shape[0]), x_norm]  # add bias component column\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "x_train_norm, x_test_norm, y_train, y_test = train_test_split(x_norm, y, test_size=0.2, stratify=y, random_state=0)\n",
    "\n",
    "step_norm = [0.0005, 0.0001, 0.00005]\n",
    "l_list_norm = []\n",
    "w_list_norm = []\n",
    "result_norm = []\n",
    "for s in step_norm:\n",
    "    start = time.time()\n",
    "    l1, w1, e1 = sgd(x_train_norm, y_train, alpha=s)\n",
    "    t1 = round(time.time() - start, 6)\n",
    "    r1 = report(x_train_norm, x_test_norm, w1)\n",
    "    l_list_norm.append(l1)\n",
    "    w_list_norm.append(w1)\n",
    "    result_norm.append(np.r_[t1, e1, r1])\n",
    "\n",
    "for i in range(len(l_list_norm)):\n",
    "    plt.plot(l_list_norm[i], label='step=' + str(step_norm[i]))\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.savefig('sgd_norm.png', dpi=270)\n",
    "plt.show()\n",
    "result_norm = np.c_[step_norm, result_norm]\n",
    "result_norm = pd.DataFrame(result_norm, columns=['step', 'time', 'epoch', 'training error', 'test error',\n",
    "                                     'training log likelihood', 'test log likelihood'])\n",
    "result_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>bias</th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00050</td>\n",
       "      <td>-0.609992</td>\n",
       "      <td>0.024295</td>\n",
       "      <td>0.009660</td>\n",
       "      <td>-0.017152</td>\n",
       "      <td>-0.005860</td>\n",
       "      <td>0.020049</td>\n",
       "      <td>-0.004125</td>\n",
       "      <td>0.010153</td>\n",
       "      <td>0.002507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>-0.572148</td>\n",
       "      <td>0.011497</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>-0.017226</td>\n",
       "      <td>-0.008645</td>\n",
       "      <td>0.010145</td>\n",
       "      <td>-0.008562</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>-0.004042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>-0.547898</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>-0.001726</td>\n",
       "      <td>-0.016812</td>\n",
       "      <td>-0.009154</td>\n",
       "      <td>0.007310</td>\n",
       "      <td>-0.009502</td>\n",
       "      <td>-0.000439</td>\n",
       "      <td>-0.005645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      step      bias  Pregnancies   Glucose  BloodPressure  SkinThickness  \\\n",
       "0  0.00050 -0.609992     0.024295  0.009660      -0.017152      -0.005860   \n",
       "1  0.00010 -0.572148     0.011497  0.000638      -0.017226      -0.008645   \n",
       "2  0.00005 -0.547898     0.007875 -0.001726      -0.016812      -0.009154   \n",
       "\n",
       "    Insulin       BMI  DiabetesPedigreeFunction       Age  \n",
       "0  0.020049 -0.004125                  0.010153  0.002507  \n",
       "1  0.010145 -0.008562                  0.001784 -0.004042  \n",
       "2  0.007310 -0.009502                 -0.000439 -0.005645  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.r_[['step', 'bias'], data.columns[:-1]]\n",
    "weights_norm = pd.DataFrame(np.c_[step_norm, w_list_norm], columns=features)\n",
    "weights_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Apply decision tree classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First apply a decision tree classifier (we recommend the one with scikit learn) on the training set. Experiment with different maximum depths, and report their error rates on the training and test data. Also report the training times required. Should the training or test set accuracies be the same on the unnormalized data as the normalized data? Why or why not? Next, apply a random forrest learner (like sklearn.ensemble.RandomForrestClassifier) to the training data. Try a few different numbers of trees (perhaps 5, 20, and 100). Report the training and test accuracies of your forests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max depth</th>\n",
       "      <th>time</th>\n",
       "      <th>training error</th>\n",
       "      <th>test error</th>\n",
       "      <th>time normalized</th>\n",
       "      <th>training error normalized</th>\n",
       "      <th>test error normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.236156</td>\n",
       "      <td>0.194805</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.236156</td>\n",
       "      <td>0.194805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.001452</td>\n",
       "      <td>0.232899</td>\n",
       "      <td>0.201299</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>0.232899</td>\n",
       "      <td>0.201299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>0.216612</td>\n",
       "      <td>0.298701</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>0.216612</td>\n",
       "      <td>0.298701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>0.146580</td>\n",
       "      <td>0.220779</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.146580</td>\n",
       "      <td>0.220779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.128664</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.128664</td>\n",
       "      <td>0.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>0.089577</td>\n",
       "      <td>0.279221</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>0.089577</td>\n",
       "      <td>0.279221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.052117</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.052117</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.032573</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.032573</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>0.016287</td>\n",
       "      <td>0.305195</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.016287</td>\n",
       "      <td>0.305195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.298701</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.298701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.298701</td>\n",
       "      <td>0.002602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.298701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max depth      time  training error  test error  time normalized  \\\n",
       "0         2.0  0.001092        0.236156    0.194805         0.001227   \n",
       "1         3.0  0.001452        0.232899    0.201299         0.001411   \n",
       "2         4.0  0.001641        0.216612    0.298701         0.001517   \n",
       "3         5.0  0.001827        0.146580    0.220779         0.001753   \n",
       "4         6.0  0.001882        0.128664    0.227273         0.001858   \n",
       "5         7.0  0.001937        0.089577    0.279221         0.001891   \n",
       "6         8.0  0.001960        0.052117    0.272727         0.002049   \n",
       "7         9.0  0.002024        0.032573    0.272727         0.002015   \n",
       "8        10.0  0.002044        0.016287    0.305195         0.002221   \n",
       "9        11.0  0.002078        0.000000    0.298701         0.002309   \n",
       "10       12.0  0.002265        0.000000    0.298701         0.002602   \n",
       "\n",
       "    training error normalized  test error normalized  \n",
       "0                    0.236156               0.194805  \n",
       "1                    0.232899               0.201299  \n",
       "2                    0.216612               0.298701  \n",
       "3                    0.146580               0.220779  \n",
       "4                    0.128664               0.227273  \n",
       "5                    0.089577               0.279221  \n",
       "6                    0.052117               0.272727  \n",
       "7                    0.032573               0.272727  \n",
       "8                    0.016287               0.305195  \n",
       "9                    0.000000               0.298701  \n",
       "10                   0.000000               0.298701  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# read data\n",
    "data = pd.read_csv('diabetes.csv', header=0)\n",
    "x = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "x_norm = normalize(x, axis=0)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_norm, y, test_size=0.2, stratify=y, random_state=0)\n",
    "x_train_norm, x_test_norm, y_train, y_test = train_test_split(x_norm, y, test_size=0.2, stratify=y, random_state=0)\n",
    "\n",
    "def error(clf):\n",
    "    start = time.time()\n",
    "    clf.fit(x_train, y_train)\n",
    "    t = round(time.time() - start, 6)\n",
    "    error_train = 1 - clf.score(x_train, y_train)\n",
    "    error_test = 1 - clf.score(x_test, y_test)\n",
    "    start = time.time()\n",
    "    clf.fit(x_train_norm, y_train)\n",
    "    t_norm = round(time.time() - start, 6)\n",
    "    error_train_norm = 1 - clf.score(x_train_norm, y_train)\n",
    "    error_test_norm = 1 - clf.score(x_test_norm, y_test)\n",
    "    return [t, error_train, error_test, t_norm, error_train_norm, error_test_norm]\n",
    "\n",
    "depth = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "error_list = []\n",
    "for d in depth:\n",
    "    clf = DecisionTreeClassifier(max_depth=d, random_state=0)\n",
    "    error_list.append(error(clf))\n",
    "table = np.c_[depth, error_list]\n",
    "df = pd.DataFrame(table, columns=['max depth', 'time', 'training error', 'test error', 'time normalized', \n",
    "                                  'training error normalized', 'test error normalized'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of trees</th>\n",
       "      <th>time</th>\n",
       "      <th>training accuracy</th>\n",
       "      <th>test accuracy</th>\n",
       "      <th>time normalized</th>\n",
       "      <th>training accuracy normalized</th>\n",
       "      <th>test accuracy normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.010930</td>\n",
       "      <td>0.970684</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.010016</td>\n",
       "      <td>0.969055</td>\n",
       "      <td>0.759740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.016744</td>\n",
       "      <td>0.983713</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.019258</td>\n",
       "      <td>0.983713</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.034018</td>\n",
       "      <td>0.995114</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.031853</td>\n",
       "      <td>0.995114</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.043586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.040965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.0</td>\n",
       "      <td>0.069231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.066586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.123632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.120456</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.811688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.145025</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.144588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>150.0</td>\n",
       "      <td>0.189842</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.180692</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.811688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>180.0</td>\n",
       "      <td>0.215974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.221788</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.805195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200.0</td>\n",
       "      <td>0.244343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.240228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.805195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number of trees      time  training accuracy  test accuracy  \\\n",
       "0              5.0  0.010930           0.970684       0.766234   \n",
       "1             10.0  0.016744           0.983713       0.785714   \n",
       "2             20.0  0.034018           0.995114       0.792208   \n",
       "3             30.0  0.043586           1.000000       0.792208   \n",
       "4             50.0  0.069231           1.000000       0.792208   \n",
       "5            100.0  0.123632           1.000000       0.805195   \n",
       "6            120.0  0.145025           1.000000       0.805195   \n",
       "7            150.0  0.189842           1.000000       0.805195   \n",
       "8            180.0  0.215974           1.000000       0.805195   \n",
       "9            200.0  0.244343           1.000000       0.805195   \n",
       "\n",
       "   time normalized  training accuracy normalized  test accuracy normalized  \n",
       "0         0.010016                      0.969055                  0.759740  \n",
       "1         0.019258                      0.983713                  0.785714  \n",
       "2         0.031853                      0.995114                  0.785714  \n",
       "3         0.040965                      1.000000                  0.785714  \n",
       "4         0.066586                      1.000000                  0.785714  \n",
       "5         0.120456                      1.000000                  0.811688  \n",
       "6         0.144588                      1.000000                  0.818182  \n",
       "7         0.180692                      1.000000                  0.811688  \n",
       "8         0.221788                      1.000000                  0.805195  \n",
       "9         0.240228                      1.000000                  0.805195  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def accuracy(rf):\n",
    "    start = time.time()\n",
    "    rf.fit(x_train, y_train)\n",
    "    t = round(time.time() - start, 6)\n",
    "    error_train = rf.score(x_train, y_train)\n",
    "    error_test = rf.score(x_test, y_test)\n",
    "    start = time.time()\n",
    "    rf.fit(x_train_norm, y_train)\n",
    "    t_norm = round(time.time() - start, 6)\n",
    "    error_train_norm = rf.score(x_train_norm, y_train)\n",
    "    error_test_norm = rf.score(x_test_norm, y_test)\n",
    "    return [t, error_train, error_test, t_norm, error_train_norm, error_test_norm]\n",
    "\n",
    "n_trees = [5, 10, 20, 30, 50, 100, 120, 150, 180, 200]\n",
    "accuracy_list = []\n",
    "for n in n_trees:\n",
    "    rf = RandomForestClassifier(n_estimators=n, random_state=0)\n",
    "    accuracy_list.append(accuracy(rf))\n",
    "table = np.c_[n_trees, accuracy_list]\n",
    "df = pd.DataFrame(table, columns=['number of trees', 'time', 'training accuracy', 'test accuracy', \n",
    "                                  'time normalized', 'training accuracy normalized', 'test accuracy normalized'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scikit learn has a neural network.MLPClassifier module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use that or something similar to train up a neural network on your $\\textbf{normalized}$ training set. Experiment a bit with the number of hidden layers (say 1-4) and number of nodes on each layer (say 10 to 100). Report the training time and accuracies on the training set and test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of hidden layers</th>\n",
       "      <th>number of nodes</th>\n",
       "      <th>time</th>\n",
       "      <th>training accuracy</th>\n",
       "      <th>test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.192563</td>\n",
       "      <td>0.726384</td>\n",
       "      <td>0.707792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.202707</td>\n",
       "      <td>0.716612</td>\n",
       "      <td>0.707792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.210962</td>\n",
       "      <td>0.754072</td>\n",
       "      <td>0.733766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.221718</td>\n",
       "      <td>0.765472</td>\n",
       "      <td>0.759740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.259377</td>\n",
       "      <td>0.755700</td>\n",
       "      <td>0.746753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0.266169</td>\n",
       "      <td>0.773616</td>\n",
       "      <td>0.759740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>0.277805</td>\n",
       "      <td>0.773616</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0.289542</td>\n",
       "      <td>0.768730</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>0.299412</td>\n",
       "      <td>0.776873</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.309553</td>\n",
       "      <td>0.775244</td>\n",
       "      <td>0.779221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.257553</td>\n",
       "      <td>0.750814</td>\n",
       "      <td>0.720779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.275059</td>\n",
       "      <td>0.768730</td>\n",
       "      <td>0.766234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>0.327642</td>\n",
       "      <td>0.776873</td>\n",
       "      <td>0.798701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.409957</td>\n",
       "      <td>0.770358</td>\n",
       "      <td>0.811688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.341866</td>\n",
       "      <td>0.778502</td>\n",
       "      <td>0.805195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>0.482317</td>\n",
       "      <td>0.785016</td>\n",
       "      <td>0.831169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>0.322341</td>\n",
       "      <td>0.780130</td>\n",
       "      <td>0.811688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "      <td>0.380193</td>\n",
       "      <td>0.789902</td>\n",
       "      <td>0.805195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>0.600876</td>\n",
       "      <td>0.791531</td>\n",
       "      <td>0.798701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.370750</td>\n",
       "      <td>0.780130</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.336358</td>\n",
       "      <td>0.770358</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.381213</td>\n",
       "      <td>0.775244</td>\n",
       "      <td>0.779221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0.359492</td>\n",
       "      <td>0.789902</td>\n",
       "      <td>0.811688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>0.340159</td>\n",
       "      <td>0.785016</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.481598</td>\n",
       "      <td>0.788274</td>\n",
       "      <td>0.824675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>0.514206</td>\n",
       "      <td>0.794788</td>\n",
       "      <td>0.811688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>0.403561</td>\n",
       "      <td>0.781759</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0.418105</td>\n",
       "      <td>0.789902</td>\n",
       "      <td>0.811688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "      <td>0.290295</td>\n",
       "      <td>0.791531</td>\n",
       "      <td>0.798701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.931233</td>\n",
       "      <td>0.825733</td>\n",
       "      <td>0.837662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.400894</td>\n",
       "      <td>0.781759</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.284858</td>\n",
       "      <td>0.773616</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>0.526010</td>\n",
       "      <td>0.791531</td>\n",
       "      <td>0.811688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>0.731995</td>\n",
       "      <td>0.796417</td>\n",
       "      <td>0.831169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.357360</td>\n",
       "      <td>0.778502</td>\n",
       "      <td>0.792208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>0.555099</td>\n",
       "      <td>0.786645</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>0.991922</td>\n",
       "      <td>0.814332</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>0.560428</td>\n",
       "      <td>0.785016</td>\n",
       "      <td>0.805195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "      <td>1.225705</td>\n",
       "      <td>0.833876</td>\n",
       "      <td>0.811688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0.775640</td>\n",
       "      <td>0.804560</td>\n",
       "      <td>0.824675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    number of hidden layers  number of nodes      time  training accuracy  \\\n",
       "0                         1               10  0.192563           0.726384   \n",
       "1                         1               20  0.202707           0.716612   \n",
       "2                         1               30  0.210962           0.754072   \n",
       "3                         1               40  0.221718           0.765472   \n",
       "4                         1               50  0.259377           0.755700   \n",
       "5                         1               60  0.266169           0.773616   \n",
       "6                         1               70  0.277805           0.773616   \n",
       "7                         1               80  0.289542           0.768730   \n",
       "8                         1               90  0.299412           0.776873   \n",
       "9                         1              100  0.309553           0.775244   \n",
       "10                        2               10  0.257553           0.750814   \n",
       "11                        2               20  0.275059           0.768730   \n",
       "12                        2               30  0.327642           0.776873   \n",
       "13                        2               40  0.409957           0.770358   \n",
       "14                        2               50  0.341866           0.778502   \n",
       "15                        2               60  0.482317           0.785016   \n",
       "16                        2               70  0.322341           0.780130   \n",
       "17                        2               80  0.380193           0.789902   \n",
       "18                        2               90  0.600876           0.791531   \n",
       "19                        2              100  0.370750           0.780130   \n",
       "20                        3               10  0.336358           0.770358   \n",
       "21                        3               20  0.381213           0.775244   \n",
       "22                        3               30  0.359492           0.789902   \n",
       "23                        3               40  0.340159           0.785016   \n",
       "24                        3               50  0.481598           0.788274   \n",
       "25                        3               60  0.514206           0.794788   \n",
       "26                        3               70  0.403561           0.781759   \n",
       "27                        3               80  0.418105           0.789902   \n",
       "28                        3               90  0.290295           0.791531   \n",
       "29                        3              100  0.931233           0.825733   \n",
       "30                        4               10  0.400894           0.781759   \n",
       "31                        4               20  0.284858           0.773616   \n",
       "32                        4               30  0.526010           0.791531   \n",
       "33                        4               40  0.731995           0.796417   \n",
       "34                        4               50  0.357360           0.778502   \n",
       "35                        4               60  0.555099           0.786645   \n",
       "36                        4               70  0.991922           0.814332   \n",
       "37                        4               80  0.560428           0.785016   \n",
       "38                        4               90  1.225705           0.833876   \n",
       "39                        4              100  0.775640           0.804560   \n",
       "\n",
       "    test accuracy  \n",
       "0        0.707792  \n",
       "1        0.707792  \n",
       "2        0.733766  \n",
       "3        0.759740  \n",
       "4        0.746753  \n",
       "5        0.759740  \n",
       "6        0.772727  \n",
       "7        0.772727  \n",
       "8        0.772727  \n",
       "9        0.779221  \n",
       "10       0.720779  \n",
       "11       0.766234  \n",
       "12       0.798701  \n",
       "13       0.811688  \n",
       "14       0.805195  \n",
       "15       0.831169  \n",
       "16       0.811688  \n",
       "17       0.805195  \n",
       "18       0.798701  \n",
       "19       0.818182  \n",
       "20       0.785714  \n",
       "21       0.779221  \n",
       "22       0.811688  \n",
       "23       0.818182  \n",
       "24       0.824675  \n",
       "25       0.811688  \n",
       "26       0.818182  \n",
       "27       0.811688  \n",
       "28       0.798701  \n",
       "29       0.837662  \n",
       "30       0.818182  \n",
       "31       0.818182  \n",
       "32       0.811688  \n",
       "33       0.831169  \n",
       "34       0.792208  \n",
       "35       0.818182  \n",
       "36       0.818182  \n",
       "37       0.805195  \n",
       "38       0.811688  \n",
       "39       0.824675  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def warn(*args, **kwargs):  # hide sklearn warnings\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn  # hide sklearn warnings\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "layers = [1, 2, 3, 4]\n",
    "n_nodes = [(i + 1) * 10 for i in range(10)]\n",
    "result = []\n",
    "for l in layers:\n",
    "    for n in n_nodes:\n",
    "        size = [n] * int(l)\n",
    "        nn = MLPClassifier(hidden_layer_sizes=size)\n",
    "        start = time.time()\n",
    "        nn.fit(x_train_norm, y_train)\n",
    "        t = time.time() - start\n",
    "        acc_train = nn.score(x_train_norm, y_train)\n",
    "        acc_test = nn.score(x_test_norm, y_test)\n",
    "        result.append([l, n, t, acc_train, acc_test])\n",
    "\n",
    "df_nn = pd.DataFrame(result, columns=['number of hidden layers', 'number of nodes', 'time', \n",
    "                                      'training accuracy', 'test accuracy'])\n",
    "df_nn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network packages tend to have many tunable parameters. Explore the effects of them on the running time and goodness of the produced hypothesis. Some of the more interesting candidates for exploration might be momentum, solver, and alpha (the L2 penalty parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>momentum</th>\n",
       "      <th>time</th>\n",
       "      <th>training accuracy</th>\n",
       "      <th>test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.348450</td>\n",
       "      <td>0.677524</td>\n",
       "      <td>0.668831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.311008</td>\n",
       "      <td>0.688925</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.312247</td>\n",
       "      <td>0.690554</td>\n",
       "      <td>0.701299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.311836</td>\n",
       "      <td>0.680782</td>\n",
       "      <td>0.668831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.313538</td>\n",
       "      <td>0.695440</td>\n",
       "      <td>0.720779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.312708</td>\n",
       "      <td>0.690554</td>\n",
       "      <td>0.688312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.312986</td>\n",
       "      <td>0.692182</td>\n",
       "      <td>0.701299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.310114</td>\n",
       "      <td>0.701954</td>\n",
       "      <td>0.707792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.309573</td>\n",
       "      <td>0.703583</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.316080</td>\n",
       "      <td>0.701954</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.313668</td>\n",
       "      <td>0.698697</td>\n",
       "      <td>0.720779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    momentum      time  training accuracy  test accuracy\n",
       "0        0.0  0.348450           0.677524       0.668831\n",
       "1        0.1  0.311008           0.688925       0.681818\n",
       "2        0.2  0.312247           0.690554       0.701299\n",
       "3        0.3  0.311836           0.680782       0.668831\n",
       "4        0.4  0.313538           0.695440       0.720779\n",
       "5        0.5  0.312708           0.690554       0.688312\n",
       "6        0.6  0.312986           0.692182       0.701299\n",
       "7        0.7  0.310114           0.701954       0.707792\n",
       "8        0.8  0.309573           0.703583       0.714286\n",
       "9        0.9  0.316080           0.701954       0.714286\n",
       "10       1.0  0.313668           0.698697       0.720779"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment different momentum\n",
    "\"\"\"\n",
    "momentum : float, default 0.9\n",
    "Momentum for gradient descent update. Should be between 0 and 1. Only used when solver=sgd.\n",
    "\"\"\"\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "momentums = [i * 0.1 for i in range(11)]\n",
    "result_m = []\n",
    "for m in momentums:\n",
    "    nn = MLPClassifier(momentum=m)\n",
    "    start = time.time()\n",
    "    nn.fit(x_train_norm, y_train)\n",
    "    t = time.time() - start\n",
    "    acc_train = nn.score(x_train_norm, y_train)\n",
    "    acc_test = nn.score(x_test_norm, y_test)\n",
    "    result_m.append([m, t, acc_train, acc_test])\n",
    "df_m = pd.DataFrame(result_m, columns=['momentum', 'time', 'training accuracy', 'test accuracy'])\n",
    "df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solver</th>\n",
       "      <th>time</th>\n",
       "      <th>training accuracy</th>\n",
       "      <th>test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.173007</td>\n",
       "      <td>0.837134</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sgd</td>\n",
       "      <td>0.291408</td>\n",
       "      <td>0.651466</td>\n",
       "      <td>0.649351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adam</td>\n",
       "      <td>0.311353</td>\n",
       "      <td>0.762215</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  solver      time  training accuracy  test accuracy\n",
       "0  lbfgs  0.173007           0.837134       0.818182\n",
       "1    sgd  0.291408           0.651466       0.649351\n",
       "2   adam  0.311353           0.762215       0.772727"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment different solver\n",
    "solvers = ['lbfgs', 'sgd', 'adam']\n",
    "result_s = []\n",
    "for s in solvers:\n",
    "    nn = MLPClassifier(solver=s)\n",
    "    start = time.time()\n",
    "    nn.fit(x_train_norm, y_train)\n",
    "    t = time.time() - start\n",
    "    acc_train = nn.score(x_train_norm, y_train)\n",
    "    acc_test = nn.score(x_test_norm, y_test)\n",
    "    result_s.append([s, t, acc_train, acc_test])\n",
    "df_s = pd.DataFrame(result_s, columns=['solver', 'time', 'training accuracy', 'test accuracy'])\n",
    "df_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>time</th>\n",
       "      <th>training accuracy</th>\n",
       "      <th>test accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.320981</td>\n",
       "      <td>0.767101</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.306654</td>\n",
       "      <td>0.768730</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.310782</td>\n",
       "      <td>0.776873</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.308720</td>\n",
       "      <td>0.770358</td>\n",
       "      <td>0.766234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     alpha      time  training accuracy  test accuracy\n",
       "0  0.01000  0.320981           0.767101       0.772727\n",
       "1  0.00100  0.306654           0.768730       0.785714\n",
       "2  0.00010  0.310782           0.776873       0.772727\n",
       "3  0.00001  0.308720           0.770358       0.766234"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment alpha : float, optional, default 0.0001\n",
    "# L2 penalty (regularization term) parameter.\n",
    "alphas = [0.01, 0.001, 0.0001, 0.00001]\n",
    "result_a = []\n",
    "for a in alphas:\n",
    "    nn = MLPClassifier(alpha=a)\n",
    "    start = time.time()\n",
    "    nn.fit(x_train_norm, y_train)\n",
    "    t = time.time() - start\n",
    "    acc_train = nn.score(x_train_norm, y_train)\n",
    "    acc_test = nn.score(x_test_norm, y_test)\n",
    "    result_a.append([a, t, acc_train, acc_test])\n",
    "df_a = pd.DataFrame(result_a, columns=['alpha', 'time', 'training accuracy', 'test accuracy'])\n",
    "df_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$a_j=\\sum w_{ji}z_i$\n",
    "\n",
    "Relu: $z_j=\\sigma (a_j)=\\texttt{max}(0, a_j)$\n",
    "\n",
    "Error of output: $E=\\frac{1}{2}(z_6-t)^2$\n",
    "\n",
    "For each node j, update: $w_{ji}=w_{ji}-\\eta \\frac{\\partial E}{\\partial w_{ji}}$\n",
    "\n",
    "For output node: $\\frac{\\partial E}{\\partial w_{ji}}=\\frac{\\partial E}{\\partial a_{j}} \\frac{\\partial a_j}{\\partial w_{ji}}=\\frac{\\partial E}{\\partial a_{j}}z_i$  where $\\frac{\\partial E}{\\partial a_{j}}=\\delta_j$\n",
    "\n",
    "For hidden nodes j, $\\frac{\\partial E}{\\partial a_j}=\\big(\\sum \\frac{\\partial E}{\\partial a_k}w_{kj}\\big)\\frac{\\partial z_j}{\\partial a_j}$\n",
    "\n",
    "$\\frac{\\partial E}{\\partial w_{ji}}=\\big(\\sum\\frac{\\partial E}{\\partial a_k}w_{kj}\\big)z_i  \\frac{\\partial z_j}{\\partial a_j}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def forward(w_ji, z_i):\n",
    "    a_j = w_ji @ z_i\n",
    "    z_j = max(0, a_j)\n",
    "    return z_j\n",
    "\n",
    "def backward(E_partial_a_k, w_k, z_j):\n",
    "    E_partial_a_j = np.array([E_partial_a_k]) @ np.array([w_k]) * (z_j > 0)\n",
    "    return E_partial_a_j\n",
    "\n",
    "w_3 = np.array([1, 1])\n",
    "w_4 = np.array([1, -1])\n",
    "w_5 = np.array([-1, -1])\n",
    "w_6 = np.array([1, 1, 1])\n",
    "z_1, z_2 = 1, 2\n",
    "inp = np.array([z_1, z_2])\n",
    "z_3 = forward(w_3, inp)\n",
    "z_4 = forward(w_4, inp)\n",
    "z_5 = forward(w_5, inp)    \n",
    "z_6 = forward(w_6, np.array([z_3, z_4, z_5]))\n",
    "# squared error\n",
    "t = 2\n",
    "E = 0.5 * ((z_6 - t) ** 2)\n",
    "print(z_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial E}{\\partial a_6} = 3-2 = 1$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 0 0 3\n"
     ]
    }
   ],
   "source": [
    "print(z_3, z_4, z_5, z_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 0])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_partial_a6 = 1 \n",
    "E_partial_w6 = E_partial_a6 * np.array([z_3, z_4, z_5])\n",
    "E_partial_w6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 0\n"
     ]
    }
   ],
   "source": [
    "E_partial_a3 = backward(E_partial_a6, w_6[0], z_3)\n",
    "E_partial_a4 = backward(E_partial_a6, w_6[1], z_4)\n",
    "E_partial_a5 = backward(E_partial_a6, w_6[2], z_5)\n",
    "print(E_partial_a3, E_partial_a4, E_partial_a5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2] [0 0] [0 0]\n"
     ]
    }
   ],
   "source": [
    "E_partial_w3 = E_partial_a3 * inp\n",
    "E_partial_w4 = E_partial_a4 * inp\n",
    "E_partial_w5 = E_partial_a5 * inp\n",
    "print(E_partial_w3, E_partial_w4, E_partial_w5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9 0.8] [ 1. -1.] [-1. -1.] [0.7 1.  1. ]\n"
     ]
    }
   ],
   "source": [
    "eta = 0.1\n",
    "w_6 = w_6 - eta * E_partial_w6\n",
    "w_3 = w_3 - eta * E_partial_w3\n",
    "w_4 = w_4 - eta * E_partial_w4\n",
    "w_5 = w_5 - eta * E_partial_w5\n",
    "print(w_3, w_4, w_5, w_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
